### 普通集合

#### 讲述一下集合类的类继承关系？TreeSet 继承了哪些接口？TreeMap 继承了哪些接口？

- Collection 集合继承关系
![](../img/collection_hierarchy.jpg)

- Map 继承关系
![](../img/map_hierarchy.jpg)

- Deque 继承关系
![](../img/deque_hierarchy.jpg)

#### ArrayList 与 LinkedList 的实现和区别？

    1. ArrayList 基于动态数组，而 LinkedList 是基于双向链表；
    2. 各个操作的时间复杂度如下：

操作 |          ArrayList 时间复杂度 |　　LinkedList 时间复杂度
---|---|---
get(int index)|　O(1) | O(n) |
add(E element)| 在不需要进行扩容的时候是 O(1)，需要扩容的话是 O(n) | O(1) |
add(int index, E element)| O(n)，因为需要移动 index 之后的数据 | O(n)，因为需要定位到 index，如果 index=0 则为 O(1) |
remove(int index)| O(n)，因为需要将 index 之前的数据往前移动 | O(n)，因为需要定位到 index |
Iterator.remove()| O(n)，因为需要将 index 之前的数据往前移动 | O(1)，无需定位，直接修改指针即可|
ListIterator.add(E element)|O(n)，因为需要移动 index 之后的数据 | O(1)，无需定位，直接修改指针即可|

#### ArrayList 的默认容量？

若在实例化 ArrayList 的时候没有指定容量，则会在第一次执行 `add` 的时候将内部数组初始化为长度 10。

#### [ArrayList 如何在循环过程中删除元素？](http://swiftlet.net/archives/743)

```java
public static void main(String[] args) {
    ArrayList<String> list = new ArrayList<String>();
    list.add("a");
    list.add("b");
    list.add("b");
    list.add("c");
    list.add("c");
    list.add("c");
    remove(list);
}
// 方法一：
public static void remove(ArrayList<String> list) {
    // 需要逆序删除，正序的话因为 remove 时数组需要进行拷贝，导致下标向前移动了一位，而使得部分元素无法被删除。
    for (int i = list.size() - 1; i >= 0; i--) {
        String s = list.get(i);
        if (s.equals("b")) {
            list.remove(s);
        }
    }
}

// 方法二：
public static void remove(ArrayList<String> list) {
    Iterator<String> it = list.iterator();
    while (it.hasNext()) {
        String s = it.next();
        if (s.equals("b")) {
            // 需要用 iterator.remove 而不能用 list.remove，否则会抛出 java.util.ConcurrentModificationException。
            it.remove();
        }
    }
}

// 有问题的方式，for-each 方式只是 Iterator 方式的语法糖，会抛出 ConcurrentModificationException。
public static void remove(ArrayList<String> list) {
    for (String s : list) {
        if (s.equals("b")) {
            list.remove(s);
        }
    }
}
```

#### LinkedList 在 `get(int index)` 操作时的优化？

会先判断 index 是在链表的左半部份还是右半部份，如果是左半部份则从头节点开始往后查找；否则从尾节点开始往前查找。
```java
private Entry<E> entry(int index) {
    if (index < 0 || index >= size)
        throw new IndexOutOfBoundsException("Index: "+index+
                                            ", Size: "+size);
    Entry<E> e = header;
    if (index < (size >> 1)) {
        for (int i = 0; i <= index; i++)
            e = e.next;
    } else {
        for (int i = size; i > index; i--)
            e = e.previous;
    }
    return e;
}
```

#### HashMap：jdk1.8 之前并发操作 HashMap 时为什么会有死循环的问题？

- 了解其数据结构、hash 冲突如何解决（链表和红黑树）

HashMap 内部维护了一个 `Entry<K,V>[]` 数组，其中 Entry 是一个键值对结构，它的 key 和 value 对应的是 HashMap.put 的 key 跟 value，同时 Entry 中还包含了一个指向下一节点的 next 属性，所以可以将 Entry 数组看作是一个链表数组。当往 HashMap 中添加数据的时候，会将给定 key 的 hash 映射到 Entry 数组的下标，新建一个 Entry 对象，并将 Entry 对象添加到链表的末尾。但是如果有过多元素都被映射到了同一个数组下标，就会导致链表的长度过长，从而在获取元素的时候时间变长，因此在 Java 8 中做了一个判断，如果链表的长度超过了 8，就会将链表转换为一棵**红黑树**（红黑树是自平衡的二叉查找树），其中树的排序默认按照 key 的 hashcode，而如果 key 的类实现了 `Comparator` 接口的话，则会按照 `compareTo` 的结果进行排序；另外如果树的元素被删除到小于等于 6 个的话，就会将树转换回链表。

- 为什么在 1.8 中把链表转化为红黑树的阈值是 8,而不是 7 或者不是 20 呢？

1. 如果选择 6 和 8（如果链表小于等于 6 时树还原转为链表，大于等于 8 转为树），中间有个差值 7 可以有效防止链表和树频繁转换。假设一下，如果设计成链表个数超过 8 则链表转换成树结构，链表个数小于 8 则树结构转换成链表，如果一个 HashMap 不停的插入、删除元素，链表个数在 8 左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低；
2. 之所以不使用 20，是因为器中节点分布在 hash 桶中的频率遵循泊松分布，桶的长度超过 8 的概率非常非常小。还有一点重要的就是由于 TreeNode 的大小大约是常规节点的两倍，因此我们仅在容器包含足够的节点以保证使用时才使用它们，当它们变得太小（由于移除或调整大小）时，它们会被转换回普通的node节点。

- 对 key.hashcode 做了哪些操作来减少哈希冲突？

因为 key 的 hash 在是通过对数组长度进行取余来映射到某个下标的，所以为了尽量避免多个 hash 映射到同一个下标，从而造成哈希冲突，HashMap 采取了一些方法来对 key.hashcode 进行重新计算，使得它们的分布会更平均。本质上都是将 hashcode 的高位比特与低位比特进行异或操作，从而使得低位比特的值更加平均，因为取余时决定结果的只是低位比特的值。

- HashMap 的数组长度为什么要保证是 2 的幂？

HashMap 选择将数组的大小设置为 2 的幂次方，这样在进行取余的时候，可以直接使用 `hash & (数组长度-1)`，提高了效率。

- 什么时候会触发扩容、扩容时避免 rehash 的优化

为了减少哈希冲突，当 HashMap 中的元素个数，也就是 size 属性大于等于一定大小的时候，会选择将 Entry 数组进行扩容，这个大小为 `loadFactor*数组长度`，其中 `loadFactor` 默认为 0.75。当进行数组扩容的时候，会新建一个原来数组长度 2 倍的新数组，并将旧数组的元素迁移到新数组上。在 Java 7 中，迁移的过程就是直接对旧数组的每一个链表计算它们在新数组的下标，然后拷贝到新数组对应下标，而在 Java 8 中，对迁移过程做了优化。

因为新的数组大小（newLength）是旧数组（oldLength）的两倍，且都是 2 的幂次方，所以 hash 在对 oldLength 和对 newLength 取余时的结果差异只取决于 hash 在 oldLength 的 1 比特所在位的比特值，例如：

```
oldLength=4 -> 0100
newLength=8 -> 1000
hash = 5    -> 0101
oldIndex = hash%oldLength = hash&(oldLength-1) = 0101 & 0011 = 0001
newIndex = hash%newLength = hash&(newLength-1) = 0101 & 0111 = 0101
```

因为 hash 的第一位比特是 1，所以 newIndex 与 oldIndex 不一样，并且比 oldIndex 大了 oldLength，因此可以直接通过：

`hash & oldLength==0` 来判断该元素的新下标是否与原来相同，并且如果不同，可以直接通过 `newIndex=oldIndex+oldLength` 来决定新的数组下标。

- `put(key, val)` 的时候是前插还是后插？

1.7 是前插，1.8 是后插。

- 1.7 resize 的时候是前插还是后插？

rehash 时将每个节点作为链表的头插入，因此会使得链表倒置。

- 并发操作 HashMap 时为什么会有死循环的问题？

存在并发操作导致 map 中的链表出现环的情况。主要是因为在 rehash 时的 transfer 操作是采用头插入的方式，使得迁移后的节点顺序与原来节点顺序相反。

情形如下：

假设有线程 t1、t2，且当前 map 中数据如下：

![image](../img/hashmap_infinite_loop_1.png)

假设 t1 和 t2 都同时触发了扩容机制，且当前 t1 执行到了 `Entry<K,V> next = e.next;` 后调度到 t2，此时 t1 的数据状态如下：

![image](../img/hashmap_infinite_loop_2.png)

t2 执行完了 transfer 方法将旧数组数据都迁移到新数组之后的数据状态如下：

![image](../img/hashmap_infinite_loop_3.png)

此时调度到 t1，继续执行 transfer 方法的：

```java
e.next = newTable[i];
newTable[i] = e;
```

从而使得数据状态变成如下：

![image](../img/hashmap_infinite_loop_4.png)

也就是出现了循环引用的状态。

```java
// 1.7 HashMap.transfer
void transfer(Entry[] newTable, boolean rehash) {
    int newCapacity = newTable.length;
    for (Entry<K,V> e : table) {
        while(null != e) {
            Entry<K,V> next = e.next; // t1 在此时停留
            if (rehash) {
                e.hash = null == e.key ? 0 : hash(e.key);
            }
            int i = indexFor(e.hash, newCapacity);
            e.next = newTable[i];
            newTable[i] = e;
            e = next;
        }
    }
}
```

- 1.7 和 1.8 中的 hash 方法有何区别？

本质上都是通过对 Key 对象 hashCode() 方法的返回值进行再次处理，以使得 hash 值的分布更加均匀。1.8 里是通过前后 16 bit 的异或操作来扩散各个比特的影响。

```java
// 1.7 hash
final int hash(Object k) {
    int h = 0;
    if (useAltHashing) {
        if (k instanceof String) {
            return sun.misc.Hashing.stringHash32((String) k);
        }
        h = hashSeed;
    }

    h ^= k.hashCode();

    // This function ensures that hashCodes that differ only by
    // constant multiples at each bit position have a bounded
    // number of collisions (approximately 8 at default load factor).
    h ^= (h >>> 20) ^ (h >>> 12);
    return h ^ (h >>> 7) ^ (h >>> 4);
}
// 1.8 hash
static final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash
static final int spread(int h) {
    return (h ^ (h >>> 16)) & HASH_BITS;
}
```
- 一些默认值

参数 | 默认值
---|---
loadFactor | 0.75
initialCapacity | 16
threshold | loadFactor*initialCapacity = 12

#### LinkedHashMap：了解基本原理、哪两种有序、如何用它实现 LRU？

另外维护了一个双向链表，链表元素为 Map 中的每一个 Entry，从而保持有序性。默认排序是按照元素的插入顺序，也可以指定使用元素的访问顺序进行排序。

LinkedHashMap 有一个构造方法，允许接收一个 Map 对象 ，并返回它的拷贝，同时保持接收 Map 对象元素的插入顺序。

构造一个 Map，包含原 Map 的所有元素，并且保留原 Map 的元素顺序（与遍历原 Map 的结果保持一致）：

`LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder)`

- 当 accessOrder 为 true，表示按照元素的*访问顺序*进行排序；
- 当 accessOrder 为 false，表示按照元素的*插入顺序*进行排序。

会修改访问顺序的操作：

- put
- get
- putAll

重复插入相同的元素不会改变该元素的插入顺序。

LinkedHashMap 继承了 HashMap，在执行了 put 等方法之后会调用 `afterNodeAccess` 方法，LinkedHashMap 实现了 `afterNodeAccess` 方法，用于对元素按照访问顺序进行排序。

```java
// 将最近一次访问的节点 e 移到链表最后
void afterNodeAccess(Node<K,V> e) { // move node to last
    LinkedHashMap.Entry<K,V> last;
    if (accessOrder && (last = tail) != e) {
        LinkedHashMap.Entry<K,V> p =
            (LinkedHashMap.Entry<K,V>)e, b = p.before, a = p.after;
        p.after = null;
        if (b == null)
            head = a;
        else
            b.after = a;
        if (a != null)
            a.before = b;
        else
            last = b;
        if (last == null)
            head = p;
        else {
            p.before = last;
            last.after = p;
        }
        tail = p;
        ++modCount;
    }
}
```

LinkedHashMap 还提供了一个 `removeEldestEntry` 方法，可以选择覆盖该方法，当该方法返回 true 的时候会移除掉链表头的元素，配合 `accessOrder` 一起使用，则可以实现移除最久没有被访问的元素。

- 使用 LinkedHashMap 实现 LRU，[Leetcode 相关问题](https://leetcode.com/problems/lru-cache/)

```java
public class LRUCache<K, V> {
    private int capacity;
    private Map<K, V> cache;
    private static int DEFAULT_INIT_CAPACITY = 16;
    private static float DEFAULT_LOAD_FACTOR = 0.75F;

    public LRUCache(int capacity) {
        this.capacity = capacity;
        this.cache = new LinkedHashMap<K, V>(DEFAULT_INIT_CAPACITY, DEFAULT_LOAD_FACTOR, true) {
            @Override
            protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
                return size() > capacity;
            }
        };
    }

    /**
     * return value or null if not contains key
     * @param key
     * @return
     */
    public V get(K key) {
        return cache.get(key);
    }

    /**
     * add {key, value} to cache
     * @param key
     * @param value
     */
    public void put(K key, V value) {
        cache.put(key, value);
    }
}
```

#### TreeMap：了解数据结构、了解其 key 对象为什么必须要实现 Compare 接口、如何用它实现一致性哈希？

底层使用红黑树维持节点的有序性，默认使用 key 作为排序的依据，所以 key 对象需要实现 `Comparable` 接口，也可以通过提供一个 Comparator 对象用于指定排序方式。

```java
return comparator==null ? ((Comparable<? super K>)k1).compareTo((K)k2) : comparator.compare((K)k1, (K)k2);
```
- [使用 TreeMap 实现一致性哈希](../code/ConsistentCache.md)

#### LinkedHashMap、TreeMap 操作时间复杂度比对

类 | 操作 | 时间复杂度
---|---|---
LinkedHashMap | put | removeEldestEntry 返回 false，O(1)；removeEldestEntry 返回 true，则是 HashMap.remove 的时间复杂度，依然是 O(1)
LinkedHashMap | get | O(1)
LinkedHashMap | containsKey | O(1)
LinkedHashMap | remove | O(1)
TreeMap | put | O(logN)
TreeMap | get | O(logN)
TreeMap | containsKey | O(logN)
TreeMap | remove | O(logN)

#### WeakHashMap

- 使用场景

WeakHashMap 的 Entry.key 是一个 WeakReference，当一个对象只有弱引用指向它的时候，该对象会在下一次 GC 时被回收。使用 WeakHashMap 作为内存缓存的时候，当 key 对象不存在其他强引用时，该 key 就会被回收，接着它对应的 value 也会被清除，从而将内存回收。

> Another common source of memory leaks is caches. Once you put an object reference into a cache, it’s easy to forget that it’s there and leave it in the cache long after it becomes irrelevant. There are several solutions to this problem. If you’re lucky enough to implement a cache for which an entry is relevant exactly so long as there are references to its key outside of the cache, represent the cache as a WeakHashMap; entries will be removed automatically after they become obsolete. Remember that WeakHashMap is useful only if the desired lifetime of cache entries is determined by external references to the key, not the value.
>
> 《Effective Java》P26，第二版


- WeakHashMap 中的 value 什么时候会被回收？

- WeakHashMap 会发生内存泄漏吗？

#### 修改 Iterator.next() 返回的对象有问题吗？

#### Collections

- `Collections.sort` 的实现