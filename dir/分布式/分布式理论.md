### CAP

一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。

- 一致性指所有节点在同一时间的数据完全一致，可以分为强/弱一致性。

1. 强一致性

对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。

2. 弱一致性：更新过的数据不一定能立刻被后续的访问看到。

另外，最终一致性是弱一致性的一种形式，表示在一段时间（*不固定时间*）后，节点间的数据会最终达到一致状态。

- 可用性

可用性指服务在正常响应时间内一直可用（例如可以正常地接受读写请求）。

- 分区容错性

分区容错性指分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性（CP without A）或可用性（AP without C）的服务。

#### 为什么说 Eureka 是 AP 而 zookeeper 是 CP 的系统？



### 一致性哈希

一致性哈希主要是为了解决在分布式的数据存储系统中，由于节点的增减而导致的数据大量迁移的问题。被广泛应用于分布式缓存，比如 memcached。

算法步骤如下：

1. 将每个节点（服务器）映射到 0 - 2^32-1 的哈希环上；
2. 对于需要存储的数据，将它们取哈希，並映射到 0 - 2^32-1 的哈希环上；
3. 在步骤 2 中的位置开始沿着哈希环进行顺时针查找，将该数据存储到查找到的第一个节点上。

![image](../img/consistent_hash.jpg)

当增加或减少节点时，需要迁移的数据只有该变更节点到其逆时针的上一个节点中的数据。这可能会导致雪崩问题。

> 如果每个节点在环上只有一个节点，那么可以想象，当某一节点从环中退出时，它原本所负责的任务将全部交由顺时针方向的下一个节点处理。例如，当 node0 退出时，它原本所负责的缓存将全部交给 node1 处理。这就意味着 node1 的访问压力会瞬间增大。设想一下，如果 node1 因为压力过大而崩溃，那么更大的压力又会向 node2 压过去，最终服务压力就像滚雪球一样越滚越大，最终导致雪崩。

- 平衡性

平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。**一致性哈希通过引进虚节点的方法解决平衡性和雪崩问题。**一个物理节点（服务器）会被映射到多个虚拟节点上，而这些虚拟节点会均匀地分布到哈希环上。

- 单调性

单调性是指哈希的结果应能够保证原有已分配的内容可以被映射到原有节点上，避免在节点增减过程中的数据迁移和不能命中。**一致性哈希就很好地解决了单调性的问题。**

#### [使用 TreeMap 实现一致性哈希](../code/ConsistentCache.md)

---
### 分布式事务

- 两种一致性

1. 2PC 协议用于保证属于多个数据分片上的操作的原子性。这些数据分片可能分布在不同的服务器上，2PC 协议保证多台服务器上的操作要么全部成功，要么全部失败。

2. Paxos 协议用于保证同一个数据分片的多个副本之间的数据一致性（即共识）。当这些副本分布到不同的数据中心时，这个需求尤其强烈。

#### 2PC（Two-phase Commi）两阶段提交

2PC 中有两个角色：协调者、参与者。

整个过程分为两个阶段，因而得名。

- 第一阶段：Prepare

1. 协调者节点向所有参与者节点询问是否可以执行提交操作，并开始等待各参与者节点的响应；
2. 参与者节点执行询问发起为止的所有事务操作，但不提交该事务；
3. 各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功（未提交，锁定资源），则它返回一个“同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个“中止”消息。

有时候，第一阶段也被称作投票阶段，即各参与者投票是否要继续接下来的提交操作。

- 第二阶段：Commit/Rollback

1. 当协调者节点从所有参与者节点获得的相应消息都为"同意"时：

	1. 协调者节点向所有参与者节点发出“正式提交”的请求；
	2. 参与者节点正式完成操作，并释放在整个事务期间内占用的资源；
	3. 参与者节点向协调者节点发送“完成”消息；
	4. 协调者节点收到所有参与者节点反馈的“完成”消息后，完成事务。

2. 失败：如果任一参与者节点在第一阶段返回的响应消息为“终止”，或者协调者节点在第一阶段的*询问超时*之前无法获取所有参与者节点的响应消息时：

	1. 协调者节点向所有参与者节点发出“回滚操作”的请求；
	2. 参与者节点将未提交的事务进行回滚，并释放在整个事务期间内占用的资源；
	3. 参与者节点向协调者节点发送“回滚完成”消息；
	4. 协调者节点收到所有参与者节点反馈的“回滚完成”消息后，取消事务。

有时候，第二阶段也被称作完成阶段，因为无论结果怎样，协调者都必须在此阶段结束当前事务。

- 优点：原理简单，便于实现

- 缺点

1. 协调者的单点失败问题；
2. 同步阻塞：参与者节点从第一阶段返回“同意”之后就锁定资源，直到第二阶段提交成功才释放资源；在提交阶段，如果有参与者节点长时间不能返回“完成”消息，协调者就要一直等待而不能执行回滚；另外协调者在等待参与者的投票时也是阻塞的；
3. 数据不一致问题：在第二阶段，如果协调者和参与者同时宕机，而又无法确定参与者执行的是 Commit 还是 Rollback 操作时（无法从其他参与者上判断），就会出现不同节点执行了不同操作的情况，从而导致数据不一致。

#### 3PC

![image](../img/3pc.png)

- 解决 2PC 的什么问题？

1. 引入参与者的超时机制，解决阻塞问题：参与者在第二阶段 PreCommit 如果发送完 ACK 之后，如果超时仍未收到第三节点 DoCommit 的 Commit/Abort 消息的话，就会自动提交；
2. 只有第一阶段 CanCommit 各参与者都返回 Yes 的情况才会进入第二阶段，进行事务的执行以及锁资源，从而减少了参与者的阻塞时间；

**3PC 仍然无法解决数据不一致的问题，因为参与者在第二阶段的超时自动提交，有可能协调者在第三阶段是给所有参与者发送了 Abort，而因为网络原因无法送达一部分参与者，导致参与者之后执行了不同的操作。**

#### Paxos

#### [Raft](http://thesecretlivesofdata.com/raft/)